{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b04b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9948a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the English language model from spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b37a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a spaCy Doc object by processing a text\n",
    "doc = nlp(\"data science and ai has great career ahead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d17ec7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "science\n",
      "and\n",
      "ai\n",
      "has\n",
      "great\n",
      "career\n",
      "ahead\n"
     ]
    }
   ],
   "source": [
    "# Displaying tokens in the document\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6f08a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data datum NOUN NNS compound xxxx True False\n",
      "science science NOUN NN ROOT xxxx True False\n",
      "and and CCONJ CC cc xxx True True\n",
      "ai ai AUX VBP aux xx True False\n",
      "has have VERB VBZ conj xxx True True\n",
      "great great ADJ JJ amod xxxx True False\n",
      "career career NOUN NN dobj xxxx True False\n",
      "ahead ahead ADV RB advmod xxxx True False\n"
     ]
    }
   ],
   "source": [
    "# Performing more detailed token analysis, including lemmatization, part-of-speech tagging, etc.\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e5c5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN\n",
      "NOUN\n",
      "CCONJ\n",
      "AUX\n",
      "VERB\n",
      "ADJ\n",
      "NOUN\n",
      "ADV\n"
     ]
    }
   ],
   "source": [
    "# Displaying only part-of-speech information\n",
    "for token in doc:\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "780f271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a large text for demonstration\n",
    "text = \"\"\"Text summarization involves condensing a given piece of text while retaining its key information \n",
    "and meaning. It is a critical component in natural language processing and aids in extracting the most \n",
    "relevant content from lengthy documents. Techniques for text summarization encompass various approaches, \n",
    "such as extractive and abstractive summarization. Extractive summarization involves selecting and \n",
    "combining essential sentences directly from the original text, while abstractive summarization generates\n",
    "concise and coherent summaries by rephrasing and interpreting the content. This process is particularly\n",
    "valuable for handling vast amounts of data, enhancing document understanding, and facilitating quicker \n",
    "comprehension. Employing advanced technologies, including machine learning and natural language \n",
    "processing models like OpenAI's GPT, text summarization contributes to efficient information retrieval \n",
    "and aids in decision-making processes across diverse domains.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f276912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the text\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9fa5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of stopwords from spaCy and punctuation marks\n",
    "stopwords = list(STOP_WORDS)\n",
    "punctuation = punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b9ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating word frequencies in the text\n",
    "word_frequencies = {}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords and word.text.lower() not in punctuation:\n",
    "        if word.text not in word_frequencies.keys():\n",
    "            word_frequencies[word.text] = 1\n",
    "        else:\n",
    "            word_frequencies[word.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41cae293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing word frequencies\n",
    "max_frequency = max(word_frequencies.values())\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word] / max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93cc4910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing sentences in the text\n",
    "sentence_tokens = [sent for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d2e406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating sentence scores based on word frequencies\n",
    "sentence_scores = {}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.text.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9283afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the top 40% of sentences based on scores\n",
    "select_length = int(len(sentence_tokens) * 0.4)\n",
    "summary = nlargest(select_length, sentence_scores, key=sentence_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18db5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the final summary as a list of words\n",
    "final_summary = [word.text for word in summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f216490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Extractive summarization involves selecting and \\ncombining essential sentences directly from the original text, while abstractive summarization generates\\nconcise and coherent summaries by rephrasing and interpreting the content.',\n",
       " \"Employing advanced technologies, including machine learning and natural language \\nprocessing models like OpenAI's GPT, text summarization contributes to efficient information retrieval \\nand aids in decision-making processes across diverse domains.\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da2919f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Extractive summarization involves selecting and \n",
       " combining essential sentences directly from the original text, while abstractive summarization generates\n",
       " concise and coherent summaries by rephrasing and interpreting the content.,\n",
       " Employing advanced technologies, including machine learning and natural language \n",
       " processing models like OpenAI's GPT, text summarization contributes to efficient information retrieval \n",
       " and aids in decision-making processes across diverse domains.]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a0479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
